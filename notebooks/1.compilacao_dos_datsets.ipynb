{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP04hbplBVFbAiC7W13d/ZA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sabvz-run/solarium_siep/blob/main/notebooks/1.compilacao_dos_datsets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Projeto A3 - Predição de Produtividade em Painéis Solares\n",
        "\n",
        "NOTEBOOK 1: PREPARAÇÃO DO DATASET SUPREMO\n",
        "\n",
        "COPILADO DOS DATASET COM OS DADOS TRATADOS E PRONTOS PARA UTILIZAÇÃO NO NOTEBOOK 2.\n",
        "\n",
        "[DATASETS NO GITHUB](https://github.com/sabvz-run/solarium_siep/tree/bd3b8a89e7edf5e7d6caeabd8999fde58f3e794f/datasets)\n"
      ],
      "metadata": {
        "id": "wahaVEGxDiJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ETAPA 1: INSTALAÇÃO E IMPORTAÇÃO DE BIBLIOTECAS\n",
        "# ============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Bibliotecas importadas com sucesso\")\n",
        "print(\"Versao Pandas:\", pd.__version__)\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBjnH4ueDh3F",
        "outputId": "0bc440b0-30bd-4bab-f1de-2523d9a848bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bibliotecas importadas com sucesso\n",
            "Versao Pandas: 2.2.2\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ETAPA 2: CARREGAMENTO DOS 9 DATASETS ORIGINAIS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nETAPA 2: CARREGANDO DATASETS ORIGINAIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# URLs base do GitHub (você vai atualizar com seus links reais)\n",
        "url_base = 'https://raw.githubusercontent.com/sabvz-run/solarium_siep/main/datasets/'\n",
        "\n",
        "# DATASET 1: Residencial 5 anos\n",
        "print(\"\\n[1/9] Carregando: geracao_5anos.csv\")\n",
        "try:\n",
        "    df1_geracao_5anos = pd.read_csv(url_base + 'geracao_5anos.csv')\n",
        "    print(f\"    Carregado: {df1_geracao_5anos.shape[0]} linhas, {df1_geracao_5anos.shape[1]} colunas\")\n",
        "except Exception as e:\n",
        "    print(f\"    ERRO: {e}\")\n",
        "    df1_geracao_5anos = None\n",
        "\n",
        "# DATASET 2: Plant 1 - Geração\n",
        "print(\"\\n[2/9] Carregando: plant1_geracao.csv\")\n",
        "try:\n",
        "    df2_plant1_geracao = pd.read_csv(url_base + 'plant1_geracao.csv')\n",
        "    print(f\"    Carregado: {df2_plant1_geracao.shape[0]} linhas, {df2_plant1_geracao.shape[1]} colunas\")\n",
        "except Exception as e:\n",
        "    print(f\"    ERRO: {e}\")\n",
        "    df2_plant1_geracao = None\n",
        "\n",
        "# DATASET 3: Plant 1 - Clima\n",
        "print(\"\\n[3/9] Carregando: plant1_clima.csv\")\n",
        "try:\n",
        "    df2_plant1_clima = pd.read_csv(url_base + 'plant1_clima.csv')\n",
        "    print(f\"    Carregado: {df2_plant1_clima.shape[0]} linhas, {df2_plant1_clima.shape[1]} colunas\")\n",
        "except Exception as e:\n",
        "    print(f\"    ERRO: {e}\")\n",
        "    df2_plant1_clima = None\n",
        "\n",
        "# DATASET 4: NASA Clima\n",
        "print(\"\\n[4/9] Carregando: nasa_clima.csv\")\n",
        "\n",
        "try:\n",
        "    df3_nasa_clima = pd.read_csv(\n",
        "        url_base + 'nasa_clima.csv',\n",
        "        header=11  # Mudar de skiprows=12 para header=12 para ler a linha 13 (index 12) como cabeçalho\n",
        "    )\n",
        "    print(f\"    Carregado com sucesso: {df3_nasa_clima.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"    ERRO carregando nasa_clima.csv: {e}\")\n",
        "    df3_nasa_clima = None\n",
        "\n",
        "\n",
        "# DATASET 5: Geração Treino\n",
        "print(\"\\n[5/9] Carregando: geracao_treino.csv\")\n",
        "try:\n",
        "    df4_geracao_treino = pd.read_csv(url_base + 'geracao_treino.csv')\n",
        "    print(f\"    Carregado: {df4_geracao_treino.shape[0]} linhas, {df4_geracao_treino.shape[1]} colunas\")\n",
        "except Exception as e:\n",
        "    print(f\"    ERRO: {e}\")\n",
        "    df4_geracao_treino = None\n",
        "\n",
        "# DATASET 6: Geração Teste\n",
        "print(\"\\n[6/9] Carregando: geracao_teste.csv\")\n",
        "try:\n",
        "    df4_geracao_teste = pd.read_csv(url_base + 'geracao_teste.csv')\n",
        "    print(f\"    Carregado: {df4_geracao_teste.shape[0]} linhas, {df4_geracao_teste.shape[1]} colunas\")\n",
        "except Exception as e:\n",
        "    print(f\"    ERRO: {e}\")\n",
        "    df4_geracao_teste = None\n",
        "\n",
        "# DATASET 7: Clima Treino\n",
        "print(\"\\n[7/9] Carregando: clima_treino.csv\")\n",
        "try:\n",
        "    df4_clima_treino = pd.read_csv(url_base + 'clima_treino.csv')\n",
        "    print(f\"    Carregado: {df4_clima_treino.shape[0]} linhas, {df4_clima_treino.shape[1]} colunas\")\n",
        "except Exception as e:\n",
        "    print(f\"    ERRO: {e}\")\n",
        "    df4_clima_treino = None\n",
        "\n",
        "# DATASET 8: Consumo Treino\n",
        "print(\"\\n[8/9] Carregando: consumo_treino.csv\")\n",
        "try:\n",
        "    df4_consumo_treino = pd.read_csv(url_base + 'consumo_treino.csv')\n",
        "    print(f\"    Carregado: {df4_consumo_treino.shape[0]} linhas, {df4_consumo_treino.shape[1]} colunas\")\n",
        "except Exception as e:\n",
        "    print(f\"    ERRO: {e}\")\n",
        "    df4_consumo_treino = None\n",
        "\n",
        "# DATASET 9: Consumo Teste\n",
        "print(\"\\n[9/9] Carregando: consumo_teste.csv\")\n",
        "try:\n",
        "    df4_consumo_teste = pd.read_csv(url_base + 'consumo_teste.csv')\n",
        "    print(f\"    Carregado: {df4_consumo_teste.shape[0]} linhas, {df4_consumo_teste.shape[1]} colunas\")\n",
        "except Exception as e:\n",
        "    print(f\"    ERRO: {e}\")\n",
        "    df4_consumo_teste = None\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CARREGAMENTO CONCLUIDO\")\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiWu9VlXGl_g",
        "outputId": "be2fe1ef-f35e-4806-fd75-b3c9bfd7a726"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ETAPA 2: CARREGANDO DATASETS ORIGINAIS\n",
            "================================================================================\n",
            "\n",
            "[1/9] Carregando: geracao_5anos.csv\n",
            "    Carregado: 364637 linhas, 2 colunas\n",
            "\n",
            "[2/9] Carregando: plant1_geracao.csv\n",
            "    Carregado: 68778 linhas, 7 colunas\n",
            "\n",
            "[3/9] Carregando: plant1_clima.csv\n",
            "    Carregado: 3182 linhas, 6 colunas\n",
            "\n",
            "[4/9] Carregando: nasa_clima.csv\n",
            "    Carregado com sucesso: (26304, 7)\n",
            "\n",
            "[5/9] Carregando: geracao_treino.csv\n",
            "    Carregado: 46704 linhas, 4 colunas\n",
            "\n",
            "[6/9] Carregando: geracao_teste.csv\n",
            "    Carregado: 336 linhas, 4 colunas\n",
            "\n",
            "[7/9] Carregando: clima_treino.csv\n",
            "    Carregado: 48408 linhas, 13 colunas\n",
            "\n",
            "[8/9] Carregando: consumo_treino.csv\n",
            "    Carregado: 46704 linhas, 2 colunas\n",
            "\n",
            "[9/9] Carregando: consumo_teste.csv\n",
            "    Carregado: 336 linhas, 2 colunas\n",
            "\n",
            "================================================================================\n",
            "CARREGAMENTO CONCLUIDO\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ETAPA 3: ANÁLISE INICIAL E PADRONIZAÇÃO\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\\nETAPA 3: ANALISE E PADRONIZACAO\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Função auxiliar para explorar estrutura dos datasets\n",
        "def explorar_dataset(df, nome):\n",
        "    if df is not None:\n",
        "        print(f\"\\n{nome}:\")\n",
        "        print(f\"  Shape: {df.shape}\")\n",
        "        print(f\"  Colunas: {list(df.columns)}\")\n",
        "        print(f\"  Tipos: {dict(df.dtypes)}\")\n",
        "        print(f\"  Primeiras linhas:\")\n",
        "        print(df.head(2))\n",
        "    else:\n",
        "        print(f\"\\n{nome}: NAO CARREGADO\")\n",
        "\n",
        "# Explorar cada dataset para entender estrutura\n",
        "explorar_dataset(df1_geracao_5anos, \"DATASET 1 - Geracao 5 anos\")\n",
        "explorar_dataset(df2_plant1_geracao, \"DATASET 2 - Plant1 Geracao\")\n",
        "explorar_dataset(df2_plant1_clima, \"DATASET 3 - Plant1 Clima\")\n",
        "explorar_dataset(df3_nasa_clima, \"DATASET 4 - NASA Clima\")\n",
        "explorar_dataset(df4_geracao_treino, \"DATASET 5 - Geracao Treino\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4rScpAtGn9S",
        "outputId": "70f35bd6-ee3c-4ed1-c658-7b16352d2c61"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ETAPA 3: ANALISE E PADRONIZACAO\n",
            "================================================================================\n",
            "\n",
            "DATASET 1 - Geracao 5 anos:\n",
            "  Shape: (364637, 2)\n",
            "  Colunas: ['1587692809.0', '0.0']\n",
            "  Tipos: {'1587692809.0': dtype('float64'), '0.0': dtype('float64')}\n",
            "  Primeiras linhas:\n",
            "   1587692809.0  0.0\n",
            "0  1.587693e+09  0.0\n",
            "1  1.587693e+09  0.0\n",
            "\n",
            "DATASET 2 - Plant1 Geracao:\n",
            "  Shape: (68778, 7)\n",
            "  Colunas: ['DATE_TIME', 'PLANT_ID', 'SOURCE_KEY', 'DC_POWER', 'AC_POWER', 'DAILY_YIELD', 'TOTAL_YIELD']\n",
            "  Tipos: {'DATE_TIME': dtype('O'), 'PLANT_ID': dtype('int64'), 'SOURCE_KEY': dtype('O'), 'DC_POWER': dtype('float64'), 'AC_POWER': dtype('float64'), 'DAILY_YIELD': dtype('float64'), 'TOTAL_YIELD': dtype('float64')}\n",
            "  Primeiras linhas:\n",
            "          DATE_TIME  PLANT_ID       SOURCE_KEY  DC_POWER  AC_POWER  \\\n",
            "0  15-05-2020 00:00   4135001  1BY6WEcLGh8j5v7       0.0       0.0   \n",
            "1  15-05-2020 00:00   4135001  1IF53ai7Xc0U56Y       0.0       0.0   \n",
            "\n",
            "   DAILY_YIELD  TOTAL_YIELD  \n",
            "0          0.0    6259559.0  \n",
            "1          0.0    6183645.0  \n",
            "\n",
            "DATASET 3 - Plant1 Clima:\n",
            "  Shape: (3182, 6)\n",
            "  Colunas: ['DATE_TIME', 'PLANT_ID', 'SOURCE_KEY', 'AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION']\n",
            "  Tipos: {'DATE_TIME': dtype('O'), 'PLANT_ID': dtype('int64'), 'SOURCE_KEY': dtype('O'), 'AMBIENT_TEMPERATURE': dtype('float64'), 'MODULE_TEMPERATURE': dtype('float64'), 'IRRADIATION': dtype('float64')}\n",
            "  Primeiras linhas:\n",
            "             DATE_TIME  PLANT_ID       SOURCE_KEY  AMBIENT_TEMPERATURE  \\\n",
            "0  2020-05-15 00:00:00   4135001  HmiyD2TTLFNqkNe            25.184316   \n",
            "1  2020-05-15 00:15:00   4135001  HmiyD2TTLFNqkNe            25.084589   \n",
            "\n",
            "   MODULE_TEMPERATURE  IRRADIATION  \n",
            "0           22.857507          0.0  \n",
            "1           22.761668          0.0  \n",
            "\n",
            "DATASET 4 - NASA Clima:\n",
            "  Shape: (26304, 7)\n",
            "  Colunas: ['YEAR', 'MO', 'DY', 'HR', 'T2M', 'ALLSKY_SFC_SW_DWN', 'RH2M']\n",
            "  Tipos: {'YEAR': dtype('int64'), 'MO': dtype('int64'), 'DY': dtype('int64'), 'HR': dtype('int64'), 'T2M': dtype('float64'), 'ALLSKY_SFC_SW_DWN': dtype('float64'), 'RH2M': dtype('float64')}\n",
            "  Primeiras linhas:\n",
            "   YEAR  MO  DY  HR    T2M  ALLSKY_SFC_SW_DWN   RH2M\n",
            "0  2022   1   1   0  22.99                0.0  86.62\n",
            "1  2022   1   1   1  22.42                0.0  90.17\n",
            "\n",
            "DATASET 5 - Geracao Treino:\n",
            "  Shape: (46704, 4)\n",
            "  Colunas: ['datetime', 'irradiance_Wm-2', 'pv_power_mw', 'panel_temp_C']\n",
            "  Tipos: {'datetime': dtype('O'), 'irradiance_Wm-2': dtype('float64'), 'pv_power_mw': dtype('float64'), 'panel_temp_C': dtype('float64')}\n",
            "  Primeiras linhas:\n",
            "              datetime  irradiance_Wm-2  pv_power_mw  panel_temp_C\n",
            "0  2017-11-03 00:00:00              0.0          0.0          7.05\n",
            "1  2017-11-03 00:30:00              0.0          0.0          7.38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ETAPA 4: PADRONIZAÇÃO DE NOMES E FORMATOS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\\nETAPA 4: PADRONIZACAO DE NOMES E FORMATOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Dicionário de mapeamento de colunas comuns\n",
        "# IMPORTANTE: Você precisa ajustar esses nomes baseado na estrutura real dos seus datasets\n",
        "# Execute a ETAPA 3 primeiro para ver os nomes reais das colunas\n",
        "\n",
        "print(\"\\nPadronizando nomes de colunas...\")\n",
        "\n",
        "# Função para padronizar nomes\n",
        "def padronizar_colunas(df, mapa_colunas):\n",
        "    if df is not None:\n",
        "        df_padronizado = df.copy()\n",
        "        df_padronizado.rename(columns=mapa_colunas, inplace=True)\n",
        "        return df_padronizado\n",
        "    return None\n",
        "\n",
        "# AJUSTE ESSES MAPEAMENTOS BASEADO NA SUA ESTRUTURA REAL\n",
        "\n",
        "# Dataset 1: geracao_5anos.csv\n",
        "mapa_df1 = {\n",
        "    # Exemplo: 'nome_original': 'nome_padrao'\n",
        "    # 'timestamp': 'data_hora',\n",
        "    # 'power': 'geracao_kw'\n",
        "}\n",
        "\n",
        "# Dataset 2: plant1_geracao.csv\n",
        "mapa_df2_ger = {\n",
        "    'DATE_TIME': 'data_hora',\n",
        "    'DC_POWER': 'geracao_kw',\n",
        "    'SOURCE_KEY': 'inversor_id'\n",
        "}\n",
        "\n",
        "# Dataset 3: plant1_clima.csv\n",
        "mapa_df2_clima = {\n",
        "    'DATE_TIME': 'data_hora',\n",
        "    'IRRADIATION': 'irradiacao',\n",
        "    'AMBIENT_TEMPERATURE': 'temperatura_ambiente',\n",
        "    'MODULE_TEMPERATURE': 'temperatura_modulo'\n",
        "}\n",
        "\n",
        "# Dataset 4: nasa_clima.csv\n",
        "mapa_df3 = {\n",
        "    'YEAR': 'ano',\n",
        "    'MO': 'mes',\n",
        "    'DY': 'dia',\n",
        "    'HR': 'hora',\n",
        "    'T2M': 'temperatura_nasa',\n",
        "    'ALLSKY_SFC_SW_DWN': 'irradiacao_nasa',\n",
        "    'RH2M': 'umidade_nasa'\n",
        "}\n",
        "\n",
        "# --- Diagnostic print for df3_nasa_clima BEFORE renaming ---\n",
        "if df3_nasa_clima is not None:\n",
        "    print(f\"  [DEBUG - ETAPA 4] Colunas de df3_nasa_clima antes da padronizacao: {list(df3_nasa_clima.columns)}\")\n",
        "df3_nasa_clima = padronizar_colunas(df3_nasa_clima, mapa_df3)\n",
        "# --- Diagnostic print for df3_nasa_clima AFTER renaming ---\n",
        "if df3_nasa_clima is not None:\n",
        "    print(f\"  [DEBUG - ETAPA 4] Colunas de df3_nasa_clima depois da padronizacao: {list(df3_nasa_clima.columns)}\")\n",
        "\n",
        "# Dataset 5-9: Electricity Demand\n",
        "mapa_df4_ger = {\n",
        "    # Ajustar conforme colunas reais\n",
        "}\n",
        "\n",
        "# Aplicar padronização\n",
        "df1_geracao_5anos = padronizar_colunas(df1_geracao_5anos, mapa_df1)\n",
        "df2_plant1_geracao = padronizar_colunas(df2_plant1_geracao, mapa_df2_ger)\n",
        "df2_plant1_clima = padronizar_colunas(df2_plant1_clima, mapa_df2_clima)\n",
        "\n",
        "print(\"Padronizacao concluida\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7FLBPB5G4Jx",
        "outputId": "609cbefa-da41-41e3-a4d6-052d14fde062"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ETAPA 4: PADRONIZACAO DE NOMES E FORMATOS\n",
            "================================================================================\n",
            "\n",
            "Padronizando nomes de colunas...\n",
            "  [DEBUG - ETAPA 4] Colunas de df3_nasa_clima antes da padronizacao: ['YEAR', 'MO', 'DY', 'HR', 'T2M', 'ALLSKY_SFC_SW_DWN', 'RH2M']\n",
            "  [DEBUG - ETAPA 4] Colunas de df3_nasa_clima depois da padronizacao: ['ano', 'mes', 'dia', 'hora', 'temperatura_nasa', 'irradiacao_nasa', 'umidade_nasa']\n",
            "Padronizacao concluida\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ETAPA 5: CONVERSÃO DE DATAS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\\nETAPA 5: CONVERSAO DE DATAS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Função para converter a coluna 'data_hora' de um DataFrame para datetime\n",
        "def converter_data_hora_df(df):\n",
        "    if df is not None and 'data_hora' in df.columns:\n",
        "        try:\n",
        "            df['data_hora'] = pd.to_datetime(df['data_hora'], errors='coerce')\n",
        "            df = df.dropna(subset=['data_hora']).reset_index(drop=True)\n",
        "            df = df.sort_values('data_hora')\n",
        "            print(f\"  Coluna 'data_hora' convertida para datetime no DataFrame.\")\n",
        "        except Exception as e:\n",
        "            print(f\"ERRO na conversão de 'data_hora' para datetime no DataFrame: {e}\")\n",
        "    return df\n",
        "\n",
        "# Função específica para construir e converter 'data_hora' no dataset da NASA\n",
        "def construir_e_converter_data_nasa(df):\n",
        "    if df is not None:\n",
        "        try:\n",
        "            # Assumindo que 'ano', 'mes', 'dia', 'hora' já estão padronizados para df3_nasa_clima\n",
        "            df['data_hora'] = pd.to_datetime(\n",
        "                df['ano'].astype(str) + '-' +\n",
        "                df['mes'].astype(str) + '-' +\n",
        "                df['dia'].astype(str) + ' ' +\n",
        "                df['hora'].astype(str).str.zfill(2) + ':00:00', # Garante formato 'HH'\n",
        "                errors='coerce'\n",
        "            )\n",
        "            df = df.dropna(subset=['data_hora']).reset_index(drop=True)\n",
        "            df = df.sort_values('data_hora')\n",
        "            print(\"  NASA 'data_hora' construida e convertida com sucesso.\")\n",
        "        except Exception as e:\n",
        "            print(\"ERRO na construção/conversão da 'data_hora' da NASA:\", e)\n",
        "    return df\n",
        "\n",
        "print(\"\\nConvertendo datas...\")\n",
        "\n",
        "# Aplicar conversão aos DataFrames que já tiveram a coluna 'data_hora' padronizada na ETAPA 4\n",
        "df1_geracao_5anos = converter_data_hora_df(df1_geracao_5anos)\n",
        "df2_plant1_geracao = converter_data_hora_df(df2_plant1_geracao)\n",
        "df2_plant1_clima = converter_data_hora_df(df2_plant1_clima)\n",
        "\n",
        "# Aplicar a função específica para o dataset da NASA\n",
        "# --- Diagnostic print for df3_nasa_clima BEFORE date conversion ---\n",
        "if df3_nasa_clima is not None:\n",
        "    print(f\"  [DEBUG - ETAPA 5] Colunas de df3_nasa_clima antes da conversao de data: {list(df3_nasa_clima.columns)}\")\n",
        "df3_nasa_clima = construir_e_converter_data_nasa(df3_nasa_clima)\n",
        "# --- Diagnostic print for df3_nasa_clima AFTER date conversion ---\n",
        "if df3_nasa_clima is not None:\n",
        "    print(f\"  [DEBUG - ETAPA 5] Colunas de df3_nasa_clima depois da conversao de data: {list(df3_nasa_clima.columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FoLH0BGG-Es",
        "outputId": "51e17ebb-8039-4243-d2a6-84644bf9581e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ETAPA 5: CONVERSAO DE DATAS\n",
            "================================================================================\n",
            "\n",
            "Convertendo datas...\n",
            "  Coluna 'data_hora' convertida para datetime no DataFrame.\n",
            "  Coluna 'data_hora' convertida para datetime no DataFrame.\n",
            "  [DEBUG - ETAPA 5] Colunas de df3_nasa_clima antes da conversao de data: ['ano', 'mes', 'dia', 'hora', 'temperatura_nasa', 'irradiacao_nasa', 'umidade_nasa']\n",
            "  NASA 'data_hora' construida e convertida com sucesso.\n",
            "  [DEBUG - ETAPA 5] Colunas de df3_nasa_clima depois da conversao de data: ['ano', 'mes', 'dia', 'hora', 'temperatura_nasa', 'irradiacao_nasa', 'umidade_nasa', 'data_hora']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ETAPA 6: CRIAÇÃO DO DATASET SUPREMO\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\\nETAPA 6: CRIACAO DO DATASET SUPREMO\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Estratégia: Começar com dataset maior e adicionar informações dos outros\n",
        "\n",
        "# Escolher dataset base (geralmente o com mais registros temporais)\n",
        "print(\"\\nEscolhendo dataset base...\")\n",
        "\n",
        "datasets_disponiveis = {\n",
        "    'geracao_5anos': df1_geracao_5anos,\n",
        "    'plant1_geracao': df2_plant1_geracao,\n",
        "    'nasa_clima': df3_nasa_clima\n",
        "}\n",
        "\n",
        "# Remover None\n",
        "datasets_disponiveis = {k: v for k, v in datasets_disponiveis.items() if v is not None}\n",
        "\n",
        "if not datasets_disponiveis:\n",
        "    print(\"ERRO: Nenhum dataset disponivel\")\n",
        "else:\n",
        "    # Pegar o maior\n",
        "    dataset_base_nome = max(datasets_disponiveis, key=lambda k: len(datasets_disponiveis[k]))\n",
        "    dataset_supremo = datasets_disponiveis[dataset_base_nome].copy()\n",
        "    print(f\"Dataset base escolhido: {dataset_base_nome} ({len(dataset_supremo)} registros)\")\n",
        "\n",
        "    # Temporary fix: Rename and convert columns if dataset_supremo originated from df1_geracao_5anos\n",
        "    if dataset_base_nome == 'geracao_5anos' and '1587692809.0' in dataset_supremo.columns:\n",
        "        print(f\"  Renaming and converting columns for {dataset_base_nome} in dataset_supremo...\")\n",
        "        dataset_supremo.rename(columns={'1587692809.0': 'data_hora', '0.0': 'geracao_kw'}, inplace=True)\n",
        "        # Convert Unix timestamp (float) to datetime\n",
        "        dataset_supremo['data_hora'] = pd.to_datetime(dataset_supremo['data_hora'], unit='s', errors='coerce')\n",
        "        dataset_supremo = dataset_supremo.dropna(subset=['data_hora'])\n",
        "        dataset_supremo = dataset_supremo.sort_values('data_hora').reset_index(drop=True)\n",
        "        print(f\"  Columns renamed and data_hora converted for {dataset_base_nome}.\")\n",
        "\n",
        "    # Merge com dados climáticos do Plant1\n",
        "    if df2_plant1_clima is not None:\n",
        "        print(\"\\nAdicionando dados climaticos Plant1...\")\n",
        "        dataset_supremo = pd.merge(\n",
        "            dataset_supremo,\n",
        "            df2_plant1_clima,\n",
        "            on='data_hora',\n",
        "            how='left',\n",
        "            suffixes=('', '_plant1')\n",
        "        )\n",
        "        print(f\"  Registros apos merge: {len(dataset_supremo)}\")\n",
        "\n",
        "    # Merge com dados da NASA\n",
        "    if df3_nasa_clima is not None:\n",
        "        print(\"\\nAdicionando dados climaticos NASA...\")\n",
        "        dataset_supremo = pd.merge(\n",
        "            dataset_supremo,\n",
        "            df3_nasa_clima[['data_hora','temperatura_nasa','irradiacao_nasa','umidade_nasa']],\n",
        "            on='data_hora',\n",
        "            how='left'\n",
        "        )\n",
        "        print(f\"  Registros apos merge: {len(dataset_supremo)}\")\n",
        "\n",
        "    # Adicionar features temporais\n",
        "    print(\"\\nCriando features temporais...\")\n",
        "    dataset_supremo['hora'] = dataset_supremo['data_hora'].dt.hour\n",
        "    dataset_supremo['dia'] = dataset_supremo['data_hora'].dt.day\n",
        "    dataset_supremo['mes'] = dataset_supremo['data_hora'].dt.month\n",
        "    dataset_supremo['ano'] = dataset_supremo['data_hora'].dt.year\n",
        "    dataset_supremo['dia_semana'] = dataset_supremo['data_hora'].dt.dayofweek\n",
        "    dataset_supremo['eh_fim_semana'] = (dataset_supremo['data_hora'].dt.dayofweek >= 5).astype(int)\n",
        "\n",
        "    print(\"  Features temporais criadas: hora, dia, mes, ano, dia_semana, eh_fim_semana\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScDF4jzvHEOf",
        "outputId": "3c5db1a9-6b27-400d-d92c-b1a3d6a81a50"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ETAPA 6: CRIACAO DO DATASET SUPREMO\n",
            "================================================================================\n",
            "\n",
            "Escolhendo dataset base...\n",
            "Dataset base escolhido: geracao_5anos (364637 registros)\n",
            "  Renaming and converting columns for geracao_5anos in dataset_supremo...\n",
            "  Columns renamed and data_hora converted for geracao_5anos.\n",
            "\n",
            "Adicionando dados climaticos Plant1...\n",
            "  Registros apos merge: 364637\n",
            "\n",
            "Adicionando dados climaticos NASA...\n",
            "  Registros apos merge: 364637\n",
            "\n",
            "Criando features temporais...\n",
            "  Features temporais criadas: hora, dia, mes, ano, dia_semana, eh_fim_semana\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# ETAPA 7: LIMPEZA E QUALIDADE DOS DADOS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\\nETAPA 7: LIMPEZA E QUALIDADE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Verificar dados ausentes\n",
        "print(\"\\nDados ausentes por coluna:\")\n",
        "print(dataset_supremo.isnull().sum())\n",
        "\n",
        "# Estatísticas descritivas\n",
        "print(\"\\nEstatisticas descritivas:\")\n",
        "print(dataset_supremo.describe())\n",
        "\n",
        "# Remover duplicatas\n",
        "print(f\"\\nRemovendo duplicatas...\")\n",
        "antes = len(dataset_supremo)\n",
        "dataset_supremo = dataset_supremo.drop_duplicates(subset=['data_hora'])\n",
        "depois = len(dataset_supremo)\n",
        "print(f\"  Removidos: {antes - depois} registros duplicados\")\n",
        "\n",
        "# Tratar valores ausentes (estratégia simples: interpolação para séries temporais)\n",
        "print(\"\\nTratando valores ausentes...\")\n",
        "colunas_numericas = dataset_supremo.select_dtypes(include=[np.number]).columns\n",
        "for col in colunas_numericas:\n",
        "    if dataset_supremo[col].isnull().sum() > 0:\n",
        "        dataset_supremo[col] = dataset_supremo[col].interpolate(method='linear', limit_direction='both')\n",
        "\n",
        "print(\"  Valores ausentes tratados com interpolacao linear\")\n",
        "\n",
        "# Verificar resultado final\n",
        "print(\"\\nVerificacao final:\")\n",
        "print(f\"  Registros totais: {len(dataset_supremo)}\")\n",
        "print(f\"  Colunas: {len(dataset_supremo.columns)}\")\n",
        "print(f\"  Periodo: {dataset_supremo['data_hora'].min()} ate {dataset_supremo['data_hora'].max()}\")\n",
        "print(f\"  Valores ausentes restantes: {dataset_supremo.isnull().sum().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16f37JE8HSi1",
        "outputId": "d4083e5b-2827-48db-981f-2e242179289f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ETAPA 7: LIMPEZA E QUALIDADE\n",
            "================================================================================\n",
            "\n",
            "Dados ausentes por coluna:\n",
            "data_hora                    0\n",
            "geracao_kw                   0\n",
            "PLANT_ID                364637\n",
            "SOURCE_KEY              364637\n",
            "temperatura_ambiente    364637\n",
            "temperatura_modulo      364637\n",
            "irradiacao              364637\n",
            "temperatura_nasa        364637\n",
            "irradiacao_nasa         364637\n",
            "umidade_nasa            364637\n",
            "hora                         0\n",
            "dia                          0\n",
            "mes                          0\n",
            "ano                          0\n",
            "dia_semana                   0\n",
            "eh_fim_semana                0\n",
            "dtype: int64\n",
            "\n",
            "Estatisticas descritivas:\n",
            "                           data_hora     geracao_kw  PLANT_ID  \\\n",
            "count                         364637  364637.000000       0.0   \n",
            "mean   2022-01-17 03:01:49.000001024       1.004481       NaN   \n",
            "min              2020-04-24 01:51:49       0.000000       NaN   \n",
            "25%              2021-03-06 14:26:49       0.000000       NaN   \n",
            "50%              2022-01-17 03:01:49       0.125928       NaN   \n",
            "75%              2022-11-29 15:36:49       1.139250       NaN   \n",
            "max              2023-10-12 04:11:49     168.201768       NaN   \n",
            "std                              NaN       1.801571       NaN   \n",
            "\n",
            "       temperatura_ambiente  temperatura_modulo  irradiacao  temperatura_nasa  \\\n",
            "count                   0.0                 0.0         0.0               0.0   \n",
            "mean                    NaN                 NaN         NaN               NaN   \n",
            "min                     NaN                 NaN         NaN               NaN   \n",
            "25%                     NaN                 NaN         NaN               NaN   \n",
            "50%                     NaN                 NaN         NaN               NaN   \n",
            "75%                     NaN                 NaN         NaN               NaN   \n",
            "max                     NaN                 NaN         NaN               NaN   \n",
            "std                     NaN                 NaN         NaN               NaN   \n",
            "\n",
            "       irradiacao_nasa  umidade_nasa           hora            dia  \\\n",
            "count              0.0           0.0  364637.000000  364637.000000   \n",
            "mean               NaN           NaN      11.499288      15.707512   \n",
            "min                NaN           NaN       0.000000       1.000000   \n",
            "25%                NaN           NaN       5.000000       8.000000   \n",
            "50%                NaN           NaN      11.000000      16.000000   \n",
            "75%                NaN           NaN      17.000000      23.000000   \n",
            "max                NaN           NaN      23.000000      31.000000   \n",
            "std                NaN           NaN       6.922384       8.830824   \n",
            "\n",
            "                 mes            ano     dia_semana  eh_fim_semana  \n",
            "count  364637.000000  364637.000000  364637.000000  364637.000000  \n",
            "mean        6.599369    2021.538212       2.999940       0.285917  \n",
            "min         1.000000    2020.000000       0.000000       0.000000  \n",
            "25%         4.000000    2021.000000       1.000000       0.000000  \n",
            "50%         7.000000    2022.000000       3.000000       0.000000  \n",
            "75%         9.000000    2022.000000       5.000000       1.000000  \n",
            "max        12.000000    2023.000000       6.000000       1.000000  \n",
            "std         3.268724       1.046612       2.000698       0.451851  \n",
            "\n",
            "Removendo duplicatas...\n",
            "  Removidos: 0 registros duplicados\n",
            "\n",
            "Tratando valores ausentes...\n",
            "  Valores ausentes tratados com interpolacao linear\n",
            "\n",
            "Verificacao final:\n",
            "  Registros totais: 364637\n",
            "  Colunas: 16\n",
            "  Periodo: 2020-04-24 01:51:49 ate 2023-10-12 04:11:49\n",
            "  Valores ausentes restantes: 2917096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar dataset limpo (só dados completos)\n",
        "dataset_limpo = dataset_supremo.dropna(subset=['geracao_kw', 'temperatura_ambiente', 'irradiacao'])\n",
        "print(f\"Dataset original: {len(dataset_supremo)} registros\")\n",
        "print(f\"Dataset limpo: {len(dataset_limpo)} registros\")\n",
        "print(f\"Período: {dataset_limpo['data_hora'].min()} até {dataset_limpo['data_hora'].max()}\")\n",
        "\n",
        "# Salvar\n",
        "dataset_limpo.to_csv('dataset_supremo_limpo.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIdLiyX1Azg4",
        "outputId": "089024d6-e32e-4f2f-f0d4-5d39498224d1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset original: 364637 registros\n",
            "Dataset limpo: 0 registros\n",
            "Período: NaT até NaT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ETAPA 8: EXPORTAÇÃO DO DATASET SUPREMO\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\\nETAPA 8: EXPORTACAO\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Salvar dataset supremo\n",
        "nome_arquivo = 'dataset_supremo.csv'\n",
        "dataset_supremo.to_csv(nome_arquivo, index=False)\n",
        "\n",
        "print(f\"\\nDataset Supremo salvo como: {nome_arquivo}\")\n",
        "print(f\"  Tamanho do arquivo: {round(dataset_supremo.memory_usage(deep=True).sum() / 1024**2, 2)} MB\")\n",
        "print(f\"  Total de registros: {len(dataset_supremo)}\")\n",
        "print(f\"  Total de colunas: {len(dataset_supremo.columns)}\")\n",
        "print(f\"\\nColunas finais:\")\n",
        "for i, col in enumerate(dataset_supremo.columns, 1):\n",
        "    print(f\"  {i}. {col}\")\n",
        "\n",
        "# Salvar também informações sobre o dataset\n",
        "info_dataset = {\n",
        "    'total_registros': len(dataset_supremo),\n",
        "    'total_colunas': len(dataset_supremo.columns),\n",
        "    'periodo_inicial': str(dataset_supremo['data_hora'].min()),\n",
        "    'periodo_final': str(dataset_supremo['data_hora'].max()),\n",
        "    'colunas': list(dataset_supremo.columns)\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('dataset_info.json', 'w') as f:\n",
        "    json.dump(info_dataset, f, indent=2)\n",
        "\n",
        "print(\"\\nInformacoes do dataset salvas em: dataset_info.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlL0a2DeHiNn",
        "outputId": "b08a0ca0-bae1-47da-9f68-c55f67d56f90"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ETAPA 8: EXPORTACAO\n",
            "================================================================================\n",
            "\n",
            "Dataset Supremo salvo como: dataset_supremo.csv\n",
            "  Tamanho do arquivo: 45.9 MB\n",
            "  Total de registros: 364637\n",
            "  Total de colunas: 16\n",
            "\n",
            "Colunas finais:\n",
            "  1. data_hora\n",
            "  2. geracao_kw\n",
            "  3. PLANT_ID\n",
            "  4. SOURCE_KEY\n",
            "  5. temperatura_ambiente\n",
            "  6. temperatura_modulo\n",
            "  7. irradiacao\n",
            "  8. temperatura_nasa\n",
            "  9. irradiacao_nasa\n",
            "  10. umidade_nasa\n",
            "  11. hora\n",
            "  12. dia\n",
            "  13. mes\n",
            "  14. ano\n",
            "  15. dia_semana\n",
            "  16. eh_fim_semana\n",
            "\n",
            "Informacoes do dataset salvas em: dataset_info.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii3NUW_yB2-L",
        "outputId": "9f91d6df-eb26-4684-f368-2292960c9eeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "ETAPA 9: PREVIEW DO DATASET FINAL\n",
            "================================================================================\n",
            "\n",
            "Primeiras 5 linhas:\n",
            "            data_hora  geracao_kw  PLANT_ID SOURCE_KEY  temperatura_ambiente  \\\n",
            "0 2020-04-24 01:51:49    0.000000       NaN        NaN                   NaN   \n",
            "1 2020-04-24 01:56:49    0.000000       NaN        NaN                   NaN   \n",
            "2 2020-04-24 02:01:49    0.000000       NaN        NaN                   NaN   \n",
            "3 2020-04-24 02:06:49    0.167167       NaN        NaN                   NaN   \n",
            "4 2020-04-24 02:11:49    0.189000       NaN        NaN                   NaN   \n",
            "\n",
            "   temperatura_modulo  irradiacao  temperatura_nasa  irradiacao_nasa  \\\n",
            "0                 NaN         NaN               NaN              NaN   \n",
            "1                 NaN         NaN               NaN              NaN   \n",
            "2                 NaN         NaN               NaN              NaN   \n",
            "3                 NaN         NaN               NaN              NaN   \n",
            "4                 NaN         NaN               NaN              NaN   \n",
            "\n",
            "   umidade_nasa  hora  dia  mes   ano  dia_semana  eh_fim_semana  \n",
            "0           NaN     1   24    4  2020           4              0  \n",
            "1           NaN     1   24    4  2020           4              0  \n",
            "2           NaN     2   24    4  2020           4              0  \n",
            "3           NaN     2   24    4  2020           4              0  \n",
            "4           NaN     2   24    4  2020           4              0  \n",
            "\n",
            "Ultimas 5 linhas:\n",
            "                 data_hora  geracao_kw  PLANT_ID SOURCE_KEY  \\\n",
            "364632 2023-10-12 03:51:49       2.012       NaN        NaN   \n",
            "364633 2023-10-12 03:56:49       2.012       NaN        NaN   \n",
            "364634 2023-10-12 04:01:49       2.012       NaN        NaN   \n",
            "364635 2023-10-12 04:06:49       2.012       NaN        NaN   \n",
            "364636 2023-10-12 04:11:49       2.012       NaN        NaN   \n",
            "\n",
            "        temperatura_ambiente  temperatura_modulo  irradiacao  \\\n",
            "364632                   NaN                 NaN         NaN   \n",
            "364633                   NaN                 NaN         NaN   \n",
            "364634                   NaN                 NaN         NaN   \n",
            "364635                   NaN                 NaN         NaN   \n",
            "364636                   NaN                 NaN         NaN   \n",
            "\n",
            "        temperatura_nasa  irradiacao_nasa  umidade_nasa  hora  dia  mes   ano  \\\n",
            "364632               NaN              NaN           NaN     3   12   10  2023   \n",
            "364633               NaN              NaN           NaN     3   12   10  2023   \n",
            "364634               NaN              NaN           NaN     4   12   10  2023   \n",
            "364635               NaN              NaN           NaN     4   12   10  2023   \n",
            "364636               NaN              NaN           NaN     4   12   10  2023   \n",
            "\n",
            "        dia_semana  eh_fim_semana  \n",
            "364632           3              0  \n",
            "364633           3              0  \n",
            "364634           3              0  \n",
            "364635           3              0  \n",
            "364636           3              0  \n",
            "\n",
            "================================================================================\n",
            "PROCESSO CONCLUIDO COM SUCESSO\n",
            "================================================================================\n",
            "\n",
            "PROXIMOS PASSOS:\n",
            "1. Baixe o arquivo dataset_supremo.csv\n",
            "2. Suba para o GitHub: github.com/sabvz-run/solarium_siep/datasets/\n",
            "3. Suba para o Google Drive e gere link publico\n",
            "4. Passe os links para continuar com o Notebook 2\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# ETAPA 9: PREVIEW DO DATASET FINAL\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\\nETAPA 9: PREVIEW DO DATASET FINAL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nPrimeiras 5 linhas:\")\n",
        "print(dataset_supremo.head())\n",
        "\n",
        "print(\"\\nUltimas 5 linhas:\")\n",
        "print(dataset_supremo.tail())\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PROCESSO CONCLUIDO COM SUCESSO\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nPROXIMOS PASSOS:\")\n",
        "print(\"1. Baixe o arquivo dataset_supremo.csv\")\n",
        "print(\"2. Suba para o GitHub: github.com/sabvz-run/solarium_siep/datasets/\")\n",
        "print(\"3. Suba para o Google Drive e gere link publico\")\n",
        "print(\"4. Passe os links para continuar com o Notebook 2\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar dataset limpo (só dados completos)\n",
        "dataset_limpo = dataset_supremo.dropna(subset=['geracao_kw', 'temperatura_ambiente', 'irradiacao'])\n",
        "print(f\"Dataset original: {len(dataset_supremo)} registros\")\n",
        "print(f\"Dataset limpo: {len(dataset_limpo)} registros\")\n",
        "print(f\"Período: {dataset_limpo['data_hora'].min()} até {dataset_limpo['data_hora'].max()}\")\n",
        "\n",
        "# Salvar\n",
        "dataset_limpo.to_csv('dataset_supremo_limpo.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VuauFkG9lfI",
        "outputId": "e877eb60-07a1-472f-c4c4-2f8912376945"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset original: 364637 registros\n",
            "Dataset limpo: 0 registros\n",
            "Período: NaT até NaT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wWpLY-5L9lNS"
      }
    }
  ]
}